Using cpu.
Number of cases: 1050
Average length of case: 14.48952380952381
Number of activities: 16
Number of events: 15214
Activity occurrences: {'ER Registration': 1050, 'ER Triage': 1053, 'ER Sepsis Triage': 1049, 'LacticAcid': 1466, 'Leucocytes': 3383, 'CRP': 3262, 'IV Liquid': 753, 'IV Antibiotics': 823, 'Admission NC': 1182, 'Release A': 671, 'Return ER': 294, 'Admission IC': 117, 'Release B': 56, 'Release C': 25, 'Release D': 24, 'Release E': 6}

Starting iteration 1/5...
Training time for Alergia: 0.0732 seconds
Total training time for process miners: 1.8945 seconds
Training time for Bayesian Classifiers: 0.0198 seconds
Evaluating fpt...
Evaluating bag...
Evaluating ngram_1...
Evaluating ngram_2...
Evaluating ngram_3...
Evaluating ngram_4...
Evaluating ngram_5...
Evaluating ngram_6...
Evaluating ngram_7...
Evaluating ngram_8...
Evaluating ngram_9...
Evaluating fallback fpt->ngram...
Evaluating hard voting...
Evaluating soft voting (2, 3, 4)...
Evaluating soft voting (2, 3, 5, 8)...
Evaluating soft voting (2, 3, 4, 5)...
Evaluating soft voting (2, 3, 4)*...
Evaluating soft voting (2, 3, 5, 8)*...
Evaluating soft voting (2, 3, 4, 5)*...
Evaluating alergia...
Evaluating bayesian train...
Evaluating bayesian test...
Evaluating bayesian t+t...
Evaluating bayesian test nonsingle...
Evaluating bayesian t+t nonsingle...
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 2.5137
Evaluating on validation set...
New best validation accuracy: 26.84%
Epoch 2/20, Average Loss: 1.7596
Evaluating on validation set...
New best validation accuracy: 40.41%
Epoch 3/20, Average Loss: 1.5438
Evaluating on validation set...
New best validation accuracy: 52.85%
Epoch 4/20, Average Loss: 1.3656
Evaluating on validation set...
New best validation accuracy: 56.39%
Epoch 5/20, Average Loss: 1.2424
Evaluating on validation set...
New best validation accuracy: 58.59%
Epoch 6/20, Average Loss: 1.1629
Evaluating on validation set...
New best validation accuracy: 60.92%
Epoch 7/20, Average Loss: 1.1043
Evaluating on validation set...
New best validation accuracy: 61.46%
Epoch 8/20, Average Loss: 1.0540
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 9/20, Average Loss: 1.0193
Evaluating on validation set...
New best validation accuracy: 63.09%
Epoch 10/20, Average Loss: 0.9884
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 11/20, Average Loss: 0.9668
Evaluating on validation set...
New best validation accuracy: 64.59%
Epoch 12/20, Average Loss: 0.9447
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 13/20, Average Loss: 0.9387
Evaluating on validation set...
New best validation accuracy: 65.00%
Epoch 14/20, Average Loss: 0.9267
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 15/20, Average Loss: 0.9163
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 16/20, Average Loss: 0.9048
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 65.00%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 1.7821
Evaluating on validation set...
New best validation accuracy: 56.55%
Epoch 2/20, Average Loss: 1.1728
Evaluating on validation set...
New best validation accuracy: 62.46%
Epoch 3/20, Average Loss: 1.0757
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 4/20, Average Loss: 1.0249
Evaluating on validation set...
New best validation accuracy: 62.96%
Epoch 5/20, Average Loss: 1.0037
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 6/20, Average Loss: 0.9890
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 7/20, Average Loss: 0.9721
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 62.96%

Iteration 1 stats:
                        Model  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3  Correct (%)  Wrong (%)  Empty (%)  Top-2  Top-3  Pred Time  Train Time  Good Preds  Tot Preds  Nb States
0                         fpt        inf     10.54        inf    inf    inf        31.15      14.27      54.59  36.84  39.86      11.54        3.06        1083       3477     4902.0
1                         bag        inf      2.60       2.48   2.15   2.94        56.47      41.80       1.73  79.73  89.53      25.80        2.45        1440       2550      161.0
2                     ngram_1      11.16     10.85      10.93  10.12  12.27        20.73      79.27       0.00  41.34  49.80      50.89       13.49         524       2528        1.0
3                     ngram_2        inf      3.66       3.68   3.07   4.43        55.10      44.90       0.00  71.40  81.72      38.10        3.13        1393       2528       17.0
4                     ngram_3        inf      3.35       3.06   2.57   3.91        57.00      42.92       0.08  74.37  83.74      29.36        2.44        1441       2528      128.0
5                     ngram_4        inf      3.28       2.65   2.20    inf        57.95      41.26       0.79  76.59  85.71      23.27        2.26        1468       2533      474.0
6                     ngram_5        inf      3.40       2.37   1.95    inf        60.78      36.38       2.84  78.28  86.83      19.07        2.34        1542       2537     1247.0
7                     ngram_6        inf      4.42        inf   1.99    inf        58.95      34.16       6.89  74.34  81.19      17.00        2.56        1498       2541     2608.0
8                     ngram_7        inf      5.71        inf   2.09    inf        55.16      31.10      13.73  67.80  74.14      15.55        3.22        1410       2556     4647.0
9                     ngram_8        inf      8.16        inf    inf    inf        50.95      28.45      20.60  61.89  66.68      14.33        3.44        1318       2587     7216.0
10                    ngram_9        inf      9.46        inf    inf    inf        47.36      24.81      27.83  56.39  60.53      13.24        3.89        1237       2612    10091.0
11        fallback fpt->ngram        inf      3.27       2.35   1.90    inf        61.07      36.05       2.88  78.37  86.92      38.31        5.41        1550       2538        NaN
12                hard voting       0.00      0.00       0.00   0.00   0.00        63.01      36.99       0.00  63.01  63.01     159.21       30.44        1593       2528        NaN
13      soft voting (2, 3, 4)        inf      2.54       2.46   2.09   3.09        63.45      36.55       0.00  82.44  91.73     149.34       20.08        1604       2528        NaN
14   soft voting (2, 3, 5, 8)        inf      2.53       2.40   2.07   3.01        63.05      36.95       0.00  82.79  91.77     161.67       15.28        1594       2528        NaN
15   soft voting (2, 3, 4, 5)        inf      2.52       2.41   2.04   3.03        63.45      36.55       0.00  82.44  91.81     170.11       13.33        1604       2528        NaN
16     soft voting (2, 3, 4)*        inf      2.57       2.47   2.09   3.02        63.73      36.12       0.16  82.16  91.38     147.51       17.87        1611       2528        NaN
17  soft voting (2, 3, 5, 8)*        inf      2.56       2.45   2.09   3.03        63.88      35.96       0.16  82.04  91.42     153.11       15.33        1615       2528        NaN
18  soft voting (2, 3, 4, 5)*        inf      2.55       2.44   2.06   3.03        64.12      35.72       0.16  82.12  91.42     161.53       13.10        1621       2528        NaN
19                    alergia        inf       inf        inf    inf    inf        50.04      49.96       0.00  69.30  80.50       4.42    73155.16        1265       2528       52.0
20             bayesian train        inf     10.54        inf    inf    inf        42.76      19.70      37.54  50.95  54.71       0.62        0.48        1081       2528        NaN
21              bayesian test       1.50      1.46       1.40   1.32   1.58        86.55      13.45       0.00  94.94  97.82       0.52        0.48        2188       2528        NaN
22               bayesian t+t       1.68      1.61       1.57   1.46   1.76        82.40      17.60       0.00  92.48  96.88       0.70        0.46        2083       2528        NaN
23    bayesian test nonsingle        inf      9.50        inf    inf    inf        41.53      13.45      45.02  49.92  52.81       0.58        0.38        1050       2528        NaN
24     bayesian t+t nonsingle        inf      6.67        inf   2.39    inf        45.49      17.60      36.91  55.58  59.97       0.70        0.42        1150       2528        NaN
25                       LSTM       2.62      2.45       2.41   2.05   3.09        63.96      36.04       0.00  81.61  91.85     114.47     4415.23        1617       2528        NaN
26                transformer       2.70      2.49       2.48   2.12   3.04        63.13      36.87       0.00  82.04  92.37      22.73      480.68        1596       2528        NaN
Starting iteration 2/5...
Training time for Alergia: 0.0194 seconds
Total training time for process miners: 2.1759 seconds
Training time for Bayesian Classifiers: 0.0205 seconds
Evaluating fpt...
Evaluating bag...
Evaluating ngram_1...
Evaluating ngram_2...
Evaluating ngram_3...
Evaluating ngram_4...
Evaluating ngram_5...
Evaluating ngram_6...
Evaluating ngram_7...
Evaluating ngram_8...
Evaluating ngram_9...
Evaluating fallback fpt->ngram...
Evaluating hard voting...
Evaluating soft voting (2, 3, 4)...
Evaluating soft voting (2, 3, 5, 8)...
Evaluating soft voting (2, 3, 4, 5)...
Evaluating soft voting (2, 3, 4)*...
Evaluating soft voting (2, 3, 5, 8)*...
Evaluating soft voting (2, 3, 4, 5)*...
Evaluating alergia...
Evaluating bayesian train...
Evaluating bayesian test...
Evaluating bayesian t+t...
Evaluating bayesian test nonsingle...
Evaluating bayesian t+t nonsingle...
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 2.4979
Evaluating on validation set...
New best validation accuracy: 29.03%
Epoch 2/20, Average Loss: 1.7077
Evaluating on validation set...
New best validation accuracy: 45.94%
Epoch 3/20, Average Loss: 1.5162
Evaluating on validation set...
New best validation accuracy: 53.98%
Epoch 4/20, Average Loss: 1.3477
Evaluating on validation set...
New best validation accuracy: 55.75%
Epoch 5/20, Average Loss: 1.2375
Evaluating on validation set...
New best validation accuracy: 56.96%
Epoch 6/20, Average Loss: 1.1728
Evaluating on validation set...
New best validation accuracy: 59.83%
Epoch 7/20, Average Loss: 1.1178
Evaluating on validation set...
New best validation accuracy: 61.20%
Epoch 8/20, Average Loss: 1.0826
Evaluating on validation set...
New best validation accuracy: 61.93%
Epoch 9/20, Average Loss: 1.0492
Evaluating on validation set...
New best validation accuracy: 62.82%
Epoch 10/20, Average Loss: 1.0137
Evaluating on validation set...
New best validation accuracy: 62.90%
Epoch 11/20, Average Loss: 0.9918
Evaluating on validation set...
New best validation accuracy: 63.83%
Epoch 12/20, Average Loss: 0.9885
Evaluating on validation set...
New best validation accuracy: 64.15%
Epoch 13/20, Average Loss: 0.9624
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 14/20, Average Loss: 0.9532
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 15/20, Average Loss: 0.9370
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 64.15%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 1.7183
Evaluating on validation set...
New best validation accuracy: 59.71%
Epoch 2/20, Average Loss: 1.1633
Evaluating on validation set...
New best validation accuracy: 62.62%
Epoch 3/20, Average Loss: 1.0766
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 4/20, Average Loss: 1.0248
Evaluating on validation set...
New best validation accuracy: 63.18%
Epoch 5/20, Average Loss: 1.0075
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 6/20, Average Loss: 0.9761
Evaluating on validation set...
New best validation accuracy: 63.30%
Epoch 7/20, Average Loss: 0.9729
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 8/20, Average Loss: 0.9601
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 9/20, Average Loss: 0.9569
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 63.30%

Iteration 2 stats:
                        Model  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3  Correct (%)  Wrong (%)  Empty (%)  Top-2  Top-3  Pred Time  Train Time  Good Preds  Tot Preds  Nb States
0                         fpt        inf      8.83        inf    inf    inf        31.52      14.78      53.70  37.97  40.32      12.39        2.96        1060       3363     4833.0
1                         bag        inf      2.53       2.41   2.06   2.91        56.29      38.33       5.38  78.40  87.06      26.89        2.63        1423       2528      153.0
2                     ngram_1      11.14     10.81      10.96   9.92  12.29        21.30      78.70       0.00  41.54  49.80      57.88       14.11         524       2460        1.0
3                     ngram_2        inf      3.64       3.56   3.01   4.29        55.69      44.31       0.00  71.63  81.99      42.01        3.30        1370       2460       17.0
4                     ngram_3        inf      3.25       2.99   2.58   3.70        57.72      42.28       0.00  74.23  83.74      31.74        2.73        1420       2460      128.0
5                     ngram_4        inf      3.00       2.53   2.12   3.45        60.40      39.03       0.57  77.74  87.81      25.07        2.42        1487       2462      475.0
6                     ngram_5        inf      3.22       2.28   1.99    inf        61.47      36.50       2.03  79.58  88.63      20.82        2.57        1514       2463     1267.0
7                     ngram_6        inf      4.01        inf   1.97    inf        60.82      33.91       5.27  76.46  83.18      18.59        2.90        1501       2468     2679.0
8                     ngram_7        inf      4.79        inf   1.99    inf        57.29      31.39      11.32  70.91  76.59      17.20       27.25        1422       2482     4759.0
9                     ngram_8        inf      7.30        inf   2.68    inf        53.70      28.81      17.50  65.52  69.96      15.80        3.72        1344       2503     7377.0
10                    ngram_9        inf      8.60        inf    inf    inf        49.09      26.32      24.59  59.16  62.59      14.62        4.24        1244       2534    10291.0
11        fallback fpt->ngram        inf      3.13       2.26   1.95    inf        61.47      36.50       2.03  79.50  88.47      42.02        5.58        1514       2463        NaN
12                hard voting       0.00      0.00       0.00   0.00   0.00        64.11      35.89       0.00  64.11  64.11     169.79       29.18        1577       2460        NaN
13      soft voting (2, 3, 4)        inf      2.46       2.38   2.05   2.88        64.35      35.65       0.00  83.70  92.89     161.78       12.34        1583       2460        NaN
14   soft voting (2, 3, 5, 8)        inf      2.44       2.35   2.02   2.89        64.55      35.45       0.00  83.82  92.80     173.17       17.00        1588       2460        NaN
15   soft voting (2, 3, 4, 5)        inf      2.43       2.36   2.02   2.87        64.59      35.41       0.00  83.33  93.13     180.05       14.66        1589       2460        NaN
16     soft voting (2, 3, 4)*        inf      2.50       2.41   2.08   2.89        64.67      35.24       0.08  83.29  92.52     162.87       12.24        1591       2460        NaN
17  soft voting (2, 3, 5, 8)*        inf      2.48       2.37   2.06   2.88        64.96      34.96       0.08  83.21  92.80     167.99       26.44        1598       2460        NaN
18  soft voting (2, 3, 4, 5)*        inf      2.47       2.37   2.05   2.87        64.92      35.00       0.08  83.09  92.68     226.12       14.52        1597       2460        NaN
19                    alergia        inf       inf        inf    inf    inf        46.95      53.05       0.00  64.59  76.54       5.18    19405.13        1155       2460       37.0
20             bayesian train        inf      8.83        inf    inf    inf        42.89      20.41      36.71  51.79  55.12       0.64        0.43        1055       2460        NaN
21              bayesian test       1.51      1.46       1.44   1.35   1.58        86.34      13.66       0.00  94.84  97.93       0.60        0.43        2124       2460        NaN
22               bayesian t+t       1.67      1.62       1.60   1.46   1.80        81.26      18.74       0.00  92.60  96.42       0.75        0.52        1999       2460        NaN
23    bayesian test nonsingle        inf     10.18        inf    inf    inf        41.14      13.66      45.20  49.63  52.72       0.62        0.39        1012       2460        NaN
24     bayesian t+t nonsingle        inf      6.61        inf   2.34    inf        46.02      18.74      35.24  57.36  61.18       0.76        0.43        1132       2460        NaN
25                       LSTM       2.66      2.44       2.41   2.04   2.91        63.90      36.10       0.00  83.29  91.99     125.86     4364.72        1572       2460        NaN
26                transformer       2.61      2.40       2.32   2.04   2.91        63.98      36.02       0.00  83.94  93.29      24.39      616.81        1574       2460        NaN
Starting iteration 3/5...
Training time for Alergia: 0.0244 seconds
Total training time for process miners: 2.2538 seconds
Training time for Bayesian Classifiers: 0.0215 seconds
Evaluating fpt...
Evaluating bag...
Evaluating ngram_1...
Evaluating ngram_2...
Evaluating ngram_3...
Evaluating ngram_4...
Evaluating ngram_5...
Evaluating ngram_6...
Evaluating ngram_7...
Evaluating ngram_8...
Evaluating ngram_9...
Evaluating fallback fpt->ngram...
Evaluating hard voting...
Evaluating soft voting (2, 3, 4)...
Evaluating soft voting (2, 3, 5, 8)...
Evaluating soft voting (2, 3, 4, 5)...
Evaluating soft voting (2, 3, 4)*...
Evaluating soft voting (2, 3, 5, 8)*...
Evaluating soft voting (2, 3, 4, 5)*...
Evaluating alergia...
Evaluating bayesian train...
Evaluating bayesian test...
Evaluating bayesian t+t...
Evaluating bayesian test nonsingle...
Evaluating bayesian t+t nonsingle...
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 2.5193
Evaluating on validation set...
New best validation accuracy: 29.91%
Epoch 2/20, Average Loss: 1.7518
Evaluating on validation set...
New best validation accuracy: 41.42%
Epoch 3/20, Average Loss: 1.5810
Evaluating on validation set...
New best validation accuracy: 49.00%
Epoch 4/20, Average Loss: 1.4967
Evaluating on validation set...
New best validation accuracy: 49.16%
Epoch 5/20, Average Loss: 1.3739
Evaluating on validation set...
New best validation accuracy: 60.14%
Epoch 6/20, Average Loss: 1.2418
Evaluating on validation set...
New best validation accuracy: 61.51%
Epoch 7/20, Average Loss: 1.1472
Evaluating on validation set...
New best validation accuracy: 62.63%
Epoch 8/20, Average Loss: 1.0934
Evaluating on validation set...
New best validation accuracy: 64.11%
Epoch 9/20, Average Loss: 1.0456
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 10/20, Average Loss: 1.0148
Evaluating on validation set...
New best validation accuracy: 65.16%
Epoch 11/20, Average Loss: 0.9790
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 12/20, Average Loss: 0.9632
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 13/20, Average Loss: 0.9463
Evaluating on validation set...
New best validation accuracy: 65.56%
Epoch 14/20, Average Loss: 0.9406
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 15/20, Average Loss: 0.9261
Evaluating on validation set...
New best validation accuracy: 66.00%
Epoch 16/20, Average Loss: 0.9181
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 17/20, Average Loss: 0.9102
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 18/20, Average Loss: 0.8965
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 66.00%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 1.7055
Evaluating on validation set...
New best validation accuracy: 59.42%
Epoch 2/20, Average Loss: 1.1746
Evaluating on validation set...
New best validation accuracy: 62.39%
Epoch 3/20, Average Loss: 1.0768
Evaluating on validation set...
New best validation accuracy: 64.72%
Epoch 4/20, Average Loss: 1.0295
Evaluating on validation set...
New best validation accuracy: 64.96%
Epoch 5/20, Average Loss: 0.9940
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 6/20, Average Loss: 0.9762
Evaluating on validation set...
New best validation accuracy: 65.52%
Epoch 7/20, Average Loss: 0.9699
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 8/20, Average Loss: 0.9533
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 9/20, Average Loss: 0.9448
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 65.52%

Iteration 3 stats:
                        Model  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3  Correct (%)  Wrong (%)  Empty (%)  Top-2  Top-3  Pred Time  Train Time  Good Preds  Tot Preds  Nb States
0                         fpt        inf      7.50        inf   2.57    inf        31.98      15.01      53.01  38.28  40.79      12.89        3.07        1010       3158     4998.0
1                         bag        inf      2.67       2.52   2.20   3.02        55.67      37.75       6.58  76.50  84.46      25.88        2.82        1336       2400      157.0
2                     ngram_1      11.35     11.03      11.26  10.18  12.30        19.91      80.09       0.00  39.47  47.48      55.91       14.59         462       2321        1.0
3                     ngram_2        inf      3.76       3.61   3.10   4.54        55.75      44.25       0.00  70.40  79.92      40.31        3.43        1294       2321       17.0
4                     ngram_3        inf      3.37       3.13   2.62   3.76        57.06      42.76       0.17  73.21  82.56      31.50        2.80        1325       2322      122.0
5                     ngram_4        inf      3.23       2.65   2.25    inf        59.88      39.30       0.82  76.58  85.67      25.35        2.62        1391       2323      469.0
6                     ngram_5        inf      3.44       2.40   2.02    inf        61.52      35.51       2.97  78.00  86.10      21.10        2.64        1429       2323     1247.0
7                     ngram_6        inf      4.25        inf   1.95    inf        58.84      33.65       7.51  74.46  80.82      18.96        3.12        1371       2330     2625.0
8                     ngram_7        inf      5.50        inf   2.04    inf        54.93      31.42      13.65  68.28  73.17      17.29        3.28        1292       2352     4693.0
9                     ngram_8        inf      6.47        inf   2.28    inf        50.61      28.31      21.08  62.24  66.23      15.97        3.94        1205       2381     7322.0
10                    ngram_9        inf      7.13        inf   2.33    inf        47.44      25.45      27.11  57.48  60.89      15.07       15.07        1139       2401    10286.0
11        fallback fpt->ngram        inf      3.31       2.33   1.94    inf        61.19      35.80       3.01  77.97  85.93      42.52        5.71        1422       2324        NaN
12                hard voting       0.00      0.00       0.00   0.00   0.00        64.61      35.21       0.17  64.61  64.61     164.75       14.12        1501       2323        NaN
13      soft voting (2, 3, 4)        inf      2.57       2.46   2.16   3.02        63.75      36.07       0.17  81.36  90.92     155.57       12.83        1481       2323        NaN
14   soft voting (2, 3, 5, 8)        inf      2.55       2.47   2.08   3.06        63.62      36.20       0.17  81.92  90.66     168.58       17.71        1478       2323        NaN
15   soft voting (2, 3, 4, 5)        inf      2.55       2.44   2.11   3.05        63.75      36.07       0.17  82.09  91.18     175.26       15.85        1481       2323        NaN
16     soft voting (2, 3, 4)*        inf      2.60       2.48   2.17   3.08        63.84      35.86       0.30  81.19  90.83     150.78       23.04        1483       2323        NaN
17  soft voting (2, 3, 5, 8)*        inf      2.60       2.53   2.18   3.09        63.58      36.12       0.30  81.15  90.31     164.62       43.78        1477       2323        NaN
18  soft voting (2, 3, 4, 5)*        inf      2.58       2.51   2.15   3.08        63.50      36.20       0.30  81.49  90.96     164.94       15.16        1475       2323        NaN
19                    alergia        inf       inf        inf    inf    inf        46.32      53.68       0.00  64.50  76.52       4.94    24391.89        1075       2321       34.0
20             bayesian train        inf      7.50        inf   2.57    inf        43.30      20.64      36.06  51.70  55.54       0.57        0.50        1005       2321        NaN
21              bayesian test       1.51      1.47       1.44   1.35   1.66        85.87      14.13       0.00  94.40  97.72       0.59        0.49        1993       2321        NaN
22               bayesian t+t       1.67      1.62       1.62   1.49   1.84        80.96      19.04       0.00  92.03  96.55       0.69        0.48        1879       2321        NaN
23    bayesian test nonsingle        inf      8.80        inf    inf    inf        42.74      14.13      43.13  51.27  54.59       0.61        0.52         992       2321        NaN
24     bayesian t+t nonsingle        inf      6.35        inf   2.28    inf        46.45      19.04      34.51  57.52  62.04       0.74        0.46        1078       2321        NaN
25                       LSTM       2.67      2.46       2.44   2.08   3.00        63.03      36.97       0.00  82.51  91.86      68.11     5161.00        1463       2321        NaN
26                transformer       2.76      2.47       2.47   2.00   3.14        63.33      36.67       0.00  82.51  91.64      22.00      610.05        1470       2321        NaN
Starting iteration 4/5...
Training time for Alergia: 0.0518 seconds
Total training time for process miners: 2.3324 seconds
Training time for Bayesian Classifiers: 0.0220 seconds
Evaluating fpt...
Evaluating bag...
Evaluating ngram_1...
Evaluating ngram_2...
Evaluating ngram_3...
Evaluating ngram_4...
Evaluating ngram_5...
Evaluating ngram_6...
Evaluating ngram_7...
Evaluating ngram_8...
Evaluating ngram_9...
Evaluating fallback fpt->ngram...
Evaluating hard voting...
Evaluating soft voting (2, 3, 4)...
Evaluating soft voting (2, 3, 5, 8)...
Evaluating soft voting (2, 3, 4, 5)...
Evaluating soft voting (2, 3, 4)*...
Evaluating soft voting (2, 3, 5, 8)*...
Evaluating soft voting (2, 3, 4, 5)*...
Evaluating alergia...
Evaluating bayesian train...
Evaluating bayesian test...
Evaluating bayesian t+t...
Evaluating bayesian test nonsingle...
Evaluating bayesian t+t nonsingle...
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 2.5342
Evaluating on validation set...
New best validation accuracy: 30.95%
Epoch 2/20, Average Loss: 1.7904
Evaluating on validation set...
New best validation accuracy: 43.72%
Epoch 3/20, Average Loss: 1.5858
Evaluating on validation set...
New best validation accuracy: 50.45%
Epoch 4/20, Average Loss: 1.4596
Evaluating on validation set...
New best validation accuracy: 56.62%
Epoch 5/20, Average Loss: 1.2711
Evaluating on validation set...
New best validation accuracy: 58.39%
Epoch 6/20, Average Loss: 1.1437
Evaluating on validation set...
New best validation accuracy: 62.11%
Epoch 7/20, Average Loss: 1.0833
Evaluating on validation set...
New best validation accuracy: 62.37%
Epoch 8/20, Average Loss: 1.0395
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 9/20, Average Loss: 1.0143
Evaluating on validation set...
New best validation accuracy: 63.53%
Epoch 10/20, Average Loss: 0.9837
Evaluating on validation set...
New best validation accuracy: 63.88%
Epoch 11/20, Average Loss: 0.9617
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 12/20, Average Loss: 0.9533
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 13/20, Average Loss: 0.9397
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 63.88%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 1.7377
Evaluating on validation set...
New best validation accuracy: 58.05%
Epoch 2/20, Average Loss: 1.1651
Evaluating on validation set...
New best validation accuracy: 61.50%
Epoch 3/20, Average Loss: 1.0686
Evaluating on validation set...
New best validation accuracy: 62.84%
Epoch 4/20, Average Loss: 1.0271
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 5/20, Average Loss: 0.9995
Evaluating on validation set...
New best validation accuracy: 62.97%
Epoch 6/20, Average Loss: 0.9817
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 7/20, Average Loss: 0.9673
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 8/20, Average Loss: 0.9518
Evaluating on validation set...
New best validation accuracy: 63.40%
Epoch 9/20, Average Loss: 0.9466
Evaluating on validation set...
New best validation accuracy: 63.44%
Epoch 10/20, Average Loss: 0.9406
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 11/20, Average Loss: 0.9297
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 12/20, Average Loss: 0.9265
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 63.44%

Iteration 4 stats:
                        Model  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3  Correct (%)  Wrong (%)  Empty (%)  Top-2  Top-3  Pred Time  Train Time  Good Preds  Tot Preds  Nb States
0                         fpt        inf      8.48        inf    inf    inf        31.55      14.29      54.16  36.84  39.82      12.81        2.96        1038       3290     5018.0
1                         bag        inf      2.59       2.46   2.10   2.93        50.36      33.40      16.24  68.98  76.56      24.94        2.71        1315       2611      159.0
2                     ngram_1      11.05     10.77      10.71  10.14  12.35        20.88      79.12       0.00  41.02  49.52      55.11       14.30         501       2399        1.0
3                     ngram_2        inf      3.64       3.48   3.11   4.24        56.57      43.43       0.00  72.45  80.99      41.65        3.27        1357       2399       17.0
4                     ngram_3        inf      3.22       2.97   2.68   3.59        58.52      41.39       0.08  74.28  82.99      31.99        2.66        1404       2399      128.0
5                     ngram_4        inf      2.96       2.50   2.18   3.41        59.96      39.38       0.67  77.04  85.96      25.32        2.47        1439       2400      475.0
6                     ngram_5        inf      3.21       2.29   2.01    inf        62.52      35.07       2.42  78.80  86.92      23.23        2.54        1501       2401     1250.0
7                     ngram_6        inf      3.95       3.62   1.97    inf        59.82      33.82       6.36  74.21  82.03      19.59        2.95        1438       2404     2617.0
8                     ngram_7        inf      5.46        inf   2.11    inf        55.37      31.90      12.73  67.86  74.78      17.47        3.35        1335       2411     4672.0
9                     ngram_8        inf      7.08        inf   2.31    inf        51.73      28.58      19.70  62.38  67.35      16.09        3.64        1258       2432     7276.0
10                    ngram_9        inf      8.01        inf    inf    inf        48.04      25.03      26.93  56.70  61.36      14.94       16.02        1186       2469    10213.0
11        fallback fpt->ngram        inf      3.09       2.19   1.93    inf        62.47      35.11       2.42  78.63  86.88      42.55        5.80        1500       2401        NaN
12                hard voting       0.00      0.00       0.00   0.00   0.00        64.36      35.60       0.04  64.36  64.36     168.44       13.50        1544       2399        NaN
13      soft voting (2, 3, 4)        inf      2.48       2.37   2.14   2.90        64.94      35.01       0.04  81.95  91.54     154.88       36.30        1558       2399        NaN
14   soft voting (2, 3, 5, 8)        inf      2.46       2.33   2.11   2.92        64.36      35.60       0.04  81.91  91.62     168.16       16.91        1544       2399        NaN
15   soft voting (2, 3, 4, 5)        inf      2.46       2.34   2.13   2.92        64.69      35.26       0.04  82.49  91.75     178.44       38.34        1552       2399        NaN
16     soft voting (2, 3, 4)*        inf      2.50       2.40   2.14   2.91        64.69      35.14       0.17  81.41  91.45     152.05       11.97        1552       2399        NaN
17  soft voting (2, 3, 5, 8)*        inf      2.48       2.37   2.14   2.84        64.65      35.18       0.17  81.28  91.08     164.59       16.49        1551       2399        NaN
18  soft voting (2, 3, 4, 5)*        inf      2.47       2.36   2.14   2.82        64.61      35.22       0.17  81.78  91.62     168.25       14.82        1550       2399        NaN
19                    alergia        inf       inf        inf    inf    inf        55.61      44.39       0.00  71.86  80.87       4.74    51802.16        1334       2399       61.0
20             bayesian train        inf      8.48        inf    inf    inf        43.02      19.84      37.14  50.77  54.86       0.60        0.57        1032       2399        NaN
21              bayesian test       1.51      1.46       1.44   1.32   1.66        86.58      13.42       0.00  94.54  97.50       0.59        0.52        2077       2399        NaN
22               bayesian t+t       1.68      1.62       1.60   1.46   1.85        81.70      18.30       0.00  92.37  96.58       0.65        0.47        1960       2399        NaN
23    bayesian test nonsingle        inf      6.64        inf   2.51    inf        41.39      13.42      45.19  49.35  52.31       0.62        0.36         993       2399        NaN
24     bayesian t+t nonsingle        inf      5.79        inf   2.13    inf        45.31      18.30      36.39  55.98  60.19       0.69        0.45        1087       2399        NaN
25                       LSTM       2.68      2.49       2.42   2.09   3.02        64.24      35.76       0.00  81.37  90.29      88.71     3623.25        1541       2399        NaN
26                transformer       2.66      2.44       2.38   2.08   2.99        63.57      36.43       0.00  81.95  91.41      23.10      812.78        1525       2399        NaN
Starting iteration 5/5...
Training time for Alergia: 0.0357 seconds
Total training time for process miners: 2.1831 seconds
Training time for Bayesian Classifiers: 0.0221 seconds
Evaluating fpt...
Evaluating bag...
Evaluating ngram_1...
Evaluating ngram_2...
Evaluating ngram_3...
Evaluating ngram_4...
Evaluating ngram_5...
Evaluating ngram_6...
Evaluating ngram_7...
Evaluating ngram_8...
Evaluating ngram_9...
Evaluating fallback fpt->ngram...
Evaluating hard voting...
Evaluating soft voting (2, 3, 4)...
Evaluating soft voting (2, 3, 5, 8)...
Evaluating soft voting (2, 3, 4, 5)...
Evaluating soft voting (2, 3, 4)*...
Evaluating soft voting (2, 3, 5, 8)*...
Evaluating soft voting (2, 3, 4, 5)*...
Evaluating alergia...
Evaluating bayesian train...
Evaluating bayesian test...
Evaluating bayesian t+t...
Evaluating bayesian test nonsingle...
Evaluating bayesian t+t nonsingle...
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 2.5209
Evaluating on validation set...
New best validation accuracy: 29.29%
Epoch 2/20, Average Loss: 1.7206
Evaluating on validation set...
New best validation accuracy: 41.60%
Epoch 3/20, Average Loss: 1.5047
Evaluating on validation set...
New best validation accuracy: 53.82%
Epoch 4/20, Average Loss: 1.3353
Evaluating on validation set...
New best validation accuracy: 57.30%
Epoch 5/20, Average Loss: 1.2215
Evaluating on validation set...
New best validation accuracy: 60.61%
Epoch 6/20, Average Loss: 1.1426
Evaluating on validation set...
New best validation accuracy: 62.22%
Epoch 7/20, Average Loss: 1.1001
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 8/20, Average Loss: 1.0583
Evaluating on validation set...
New best validation accuracy: 63.07%
Epoch 9/20, Average Loss: 1.0271
Evaluating on validation set...
New best validation accuracy: 64.13%
Epoch 10/20, Average Loss: 0.9986
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 11/20, Average Loss: 1.0097
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 12/20, Average Loss: 0.9645
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 64.13%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 1.7068
Evaluating on validation set...
New best validation accuracy: 60.57%
Epoch 2/20, Average Loss: 1.1735
Evaluating on validation set...
New best validation accuracy: 62.56%
Epoch 3/20, Average Loss: 1.0803
Evaluating on validation set...
New best validation accuracy: 63.54%
Epoch 4/20, Average Loss: 1.0371
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 5/20, Average Loss: 1.0074
Evaluating on validation set...
New best validation accuracy: 64.13%
Epoch 6/20, Average Loss: 0.9922
Evaluating on validation set...
New best validation accuracy: 65.20%
Epoch 7/20, Average Loss: 0.9724
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 8/20, Average Loss: 0.9576
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 9/20, Average Loss: 0.9481
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 65.20%

Iteration 5 stats:
                        Model  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3  Correct (%)  Wrong (%)  Empty (%)  Top-2  Top-3  Pred Time  Train Time  Good Preds  Tot Preds  Nb States
0                         fpt        inf      7.55        inf    inf    inf        31.59      13.33      55.08  37.01  39.44      12.50       19.20        1107       3504     4922.0
1                         bag        inf      2.55       2.39   2.03   3.00        51.98      34.16      13.86  71.11  78.81      25.70        2.66        1418       2728      155.0
2                     ngram_1      11.20     10.90      11.35  10.15  12.25        21.47      78.53       0.00  41.87  50.22      55.88       14.53         545       2539        1.0
3                     ngram_2        inf      3.52       3.50   2.93   4.12        56.40      43.60       0.00  72.12  81.80      41.76        3.33        1432       2539       17.0
4                     ngram_3        inf      3.27       3.01   2.50   3.54        58.57      41.39       0.04  74.32  83.54      32.05        2.68        1487       2539      128.0
5                     ngram_4        inf      3.00       2.58   2.05   3.61        60.38      38.64       0.98  77.94  86.06      25.28        2.43        1533       2539      465.0
6                     ngram_5        inf      3.33       2.36   1.92    inf        62.46      34.67       2.87  79.06  86.58      20.89        2.60        1587       2541     1240.0
7                     ngram_6        inf      4.08        inf   1.88    inf        59.92      33.16       6.92  74.66  81.45      18.77        2.75        1525       2545     2598.0
8                     ngram_7        inf      4.63        inf   1.94    inf        55.33      31.13      13.54  68.40  73.93      17.16        3.25        1422       2570     4627.0
9                     ngram_8        inf      6.30        inf   2.28    inf        51.78      27.98      20.25  62.21  66.46      15.73        3.80        1340       2588     7198.0
10                    ngram_9        inf      7.02        inf   2.38    inf        47.89      23.74      28.38  56.64  60.21      14.92        4.32        1259       2629    10081.0
11        fallback fpt->ngram        inf      3.20       2.28   1.82    inf        62.53      34.59       2.87  79.10  86.74      42.18        5.62        1589       2541        NaN
12                hard voting       0.00      0.00       0.00   0.00   0.00        64.47      35.49       0.04  64.47  64.47     168.62       13.18        1637       2539        NaN
13      soft voting (2, 3, 4)        inf      2.47       2.38   1.98   2.88        64.63      35.33       0.04  83.46  91.49     158.08       12.51        1641       2539        NaN
14   soft voting (2, 3, 5, 8)        inf      2.45       2.38   1.98   2.88        64.75      35.21       0.04  83.02  91.49     169.11       40.09        1644       2539        NaN
15   soft voting (2, 3, 4, 5)        inf      2.44       2.37   1.95   2.87        64.32      35.64       0.04  83.65  91.73     176.19       14.92        1633       2539        NaN
16     soft voting (2, 3, 4)*        inf      2.52       2.38   1.98   2.87        64.43      35.29       0.28  82.99  91.10     154.35       12.33        1636       2539        NaN
17  soft voting (2, 3, 5, 8)*        inf      2.51       2.38   1.97   2.87        65.10      34.62       0.28  82.91  91.06     161.57       25.91        1653       2539        NaN
18  soft voting (2, 3, 4, 5)*        inf      2.50       2.38   1.96   2.87        64.55      35.17       0.28  83.54  91.41     169.99       14.57        1639       2539        NaN
19                    alergia        inf       inf        inf    inf    inf        55.97      44.03       0.00  71.33  80.43       4.76    35727.98        1421       2539       53.0
20             bayesian train        inf      7.55        inf    inf    inf        43.64      18.35      38.01  51.04  54.35       0.59        0.55        1108       2539        NaN
21              bayesian test       1.48      1.44       1.40   1.32   1.58        87.08      12.92       0.00  95.00  97.95       0.65        0.73        2211       2539        NaN
22               bayesian t+t       1.64      1.59       1.57   1.46   1.76        82.55      17.45       0.00  92.60  96.57       0.65        0.46        2096       2539        NaN
23    bayesian test nonsingle        inf      8.59        inf    inf    inf        41.00      12.92      46.08  48.92  51.87       0.64        0.41        1041       2539        NaN
24     bayesian t+t nonsingle        inf      5.77        inf   2.13    inf        45.33      17.45      37.22  55.38  59.35       0.76        0.45        1151       2539        NaN
25                       LSTM       2.73      2.48       2.44   2.09   2.99        64.67      35.33       0.00  82.55  90.71     118.24     3384.68        1642       2539        NaN
26                transformer       2.62      2.39       2.34   1.95   2.92        63.92      36.08       0.00  81.96  90.98      23.32      606.62        1623       2539        NaN

                        Model  Mean Accuracy (%)   Std  Top-2 (%)  Top-3 (%)  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3   States  Pred Time  Train Time
0                         fpt              31.56  0.27      37.39      40.05        inf      8.58        inf    inf    inf   4922.0      12.43        6.25
1                         bag              54.15  2.50      74.94      83.29        inf      2.59       2.45   2.11   2.96    155.0      25.84        2.66
2                     ngram_1              20.86  0.55      41.05      49.36      11.18     10.87      11.04  10.10  12.29      1.0      55.13       14.20
3                     ngram_2              55.90  0.53      71.60      81.29        inf      3.64       3.57   3.04   4.32     17.0      40.77        3.29
4                     ngram_3              57.78  0.68      74.08      83.31        inf      3.29       3.03   2.59   3.70    128.0      31.33        2.66
5                     ngram_4              59.71  0.90      77.18      86.24        inf      3.10       2.58   2.16    inf    465.0      24.86        2.44
6                     ngram_5              61.75  0.66      78.75      87.01        inf      3.32       2.34   1.98    inf   1240.0      21.02        2.54
7                     ngram_6              59.67  0.72      74.83      81.73        inf      4.14        inf   1.95    inf   2598.0      18.58        2.86
8                     ngram_7              55.62  0.85      68.65      74.52        inf      5.22        inf   2.03    inf   4627.0      16.93        8.07
9                     ngram_8              51.75  1.07      62.85      67.34        inf      7.06        inf    inf    inf   7198.0      15.59        3.71
10                    ngram_9              47.96  0.62      57.27      61.12        inf      8.04        inf    inf    inf  10081.0      14.56        8.71
11        fallback fpt->ngram              61.75  0.63      78.71      86.99        inf      3.20       2.28   1.91    inf      NaN      41.51        5.62
12                hard voting              64.11  0.57      64.11      64.11       0.00      0.00       0.00   0.00   0.00      NaN     166.16       20.08
13      soft voting (2, 3, 4)              64.23  0.55      82.58      91.71        inf      2.50       2.41   2.08   2.95      NaN     155.93       18.81
14   soft voting (2, 3, 5, 8)              64.07  0.63      82.69      91.67        inf      2.49       2.39   2.05   2.95      NaN     168.14       21.40
15   soft voting (2, 3, 4, 5)              64.16  0.48      82.80      91.92        inf      2.48       2.38   2.05   2.95      NaN     176.01       19.42
16     soft voting (2, 3, 4)*              64.27  0.41      82.21      91.46        inf      2.54       2.43   2.09   2.95      NaN     153.51       15.49
17  soft voting (2, 3, 5, 8)*              64.44  0.60      82.12      91.33        inf      2.53       2.42   2.09   2.94      NaN     162.38       25.59
18  soft voting (2, 3, 4, 5)*              64.34  0.49      82.40      91.62        inf      2.52       2.41   2.07   2.94      NaN     178.16       14.43
19                    alergia              50.98  4.13      68.32      78.97        inf       inf        inf    inf    inf     53.0       4.81    40896.46
20                       LSTM              63.96  0.54      82.27      91.34       2.67      2.46       2.42   2.07   3.00      0.0     103.08     4189.77
21                transformer              63.59  0.33      82.48      91.94       2.67      2.44       2.40   2.04   3.00      0.0      23.11      625.39
22             bayesian train              43.12  0.31      51.25      54.91        inf      8.58        inf    inf    inf      NaN       0.60        0.51
23              bayesian test              86.48  0.39      94.74      97.78       1.50      1.46       1.42   1.33   1.61      NaN       0.59        0.53
24               bayesian t+t              81.77  0.62      92.42      96.60       1.67      1.61       1.59   1.47   1.80      NaN       0.69        0.48
25    bayesian test nonsingle              41.56  0.62      49.82      52.86        inf      8.74        inf    inf    inf      NaN       0.61        0.41
26     bayesian t+t nonsingle              45.72  0.44      56.36      60.55        inf      6.24        inf   2.25    inf      NaN       0.73        0.44
