Using cpu.
Number of cases: 30
Average length of case: 1.8
Number of activities: 2
Number of events: 54
Activity occurrences: {'a': 28, 'b': 26}

[DEBUG] Initialized prediction_vectors_memory (will store per-strategy prediction vectors)
Starting iteration 1/5...
[DEBUG] Stored baseline actual vector | iteration=1 | len=91 | sample=['a', 'a', 'a', 'a', '__stop__', 'a', 'a', 'b', '__stop__', 'b']
Training time for Alergia: 0.0001 seconds
Total training time for process miners: 0.0215 seconds
Training time for Bayesian Classifiers: 0.0001 seconds
Evaluating fpt...
[DEBUG] Stored preds | strategy=fpt | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating bag...
[DEBUG] Stored preds | strategy=bag | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_1...
[DEBUG] Stored preds | strategy=ngram_1 | iteration=1 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
Evaluating ngram_2...
[DEBUG] Stored preds | strategy=ngram_2 | iteration=1 | preds_len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__', '__stop__', 'b']
Evaluating ngram_3...
[DEBUG] Stored preds | strategy=ngram_3 | iteration=1 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating ngram_4...
[DEBUG] Stored preds | strategy=ngram_4 | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_5...
[DEBUG] Stored preds | strategy=ngram_5 | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_6...
[DEBUG] Stored preds | strategy=ngram_6 | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_7...
[DEBUG] Stored preds | strategy=ngram_7 | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_8...
[DEBUG] Stored preds | strategy=ngram_8 | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_9...
[DEBUG] Stored preds | strategy=ngram_9 | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating fallback fpt->ngram...
[DEBUG] Stored preds | strategy=fallback fpt->ngram | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating hard voting...
[DEBUG] Stored preds | strategy=hard voting | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4) | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8) | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5) | iteration=1 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4)* | iteration=1 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8)* | iteration=1 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5)* | iteration=1 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating alergia...
[DEBUG] Stored preds | strategy=alergia | iteration=1 | preds_len=91 | sample=['b', '__stop__', 'b', '__stop__', 'b', 'b', '__stop__', 'b', '__stop__', 'b']
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 3.8950
Evaluating on validation set...
New best validation accuracy: 23.08%
Epoch 2/20, Average Loss: 3.8438
Evaluating on validation set...
New best validation accuracy: 27.47%
Epoch 3/20, Average Loss: 3.7641
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 4/20, Average Loss: 3.6375
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 5/20, Average Loss: 3.4096
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 27.47%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 3.9678
Evaluating on validation set...
New best validation accuracy: 14.29%
Epoch 2/20, Average Loss: 2.4166
Evaluating on validation set...
New best validation accuracy: 29.67%
Epoch 3/20, Average Loss: 1.8312
Evaluating on validation set...
New best validation accuracy: 31.87%
Epoch 4/20, Average Loss: 1.4380
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 5/20, Average Loss: 1.3444
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 6/20, Average Loss: 1.2098
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 31.87%
[DEBUG] NN stored preds | model=LSTM | iter=1 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
[DEBUG] NN stored preds | model=transformer | iter=1 | preds_len=91 | sample=['a', 'a', 'a', '__stop__', '__stop__', 'a', 'a', 'a', '__stop__', 'a']
[ITER DEBUG] After iteration 1 summary counts (per strategy): {'actual': 1, 'fpt': 1, 'bag': 1, 'ngram_1': 1, 'ngram_2': 1, 'ngram_3': 1, 'ngram_4': 1, 'ngram_5': 1, 'ngram_6': 1, 'ngram_7': 1, 'ngram_8': 1, 'ngram_9': 1, 'fallback fpt->ngram': 1, 'hard voting': 1, 'soft voting (2, 3, 4)': 1, 'soft voting (2, 3, 5, 8)': 1, 'soft voting (2, 3, 4, 5)': 1, 'soft voting (2, 3, 4)*': 1, 'soft voting (2, 3, 5, 8)*': 1, 'soft voting (2, 3, 4, 5)*': 1, 'alergia': 1, 'LSTM': 1, 'transformer': 1}
[ITER DEBUG] sample preds | strategy=fpt | len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=bag | len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=ngram_1 | len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_2 | len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_3 | len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__']
Starting iteration 2/5...
[DEBUG] Stored baseline actual vector | iteration=2 | len=91 | sample=['a', 'a', 'a', 'a', '__stop__', 'a', 'a', 'b', '__stop__', 'b']
Training time for Alergia: 0.0001 seconds
Total training time for process miners: 0.0073 seconds
Training time for Bayesian Classifiers: 0.0001 seconds
Evaluating fpt...
[DEBUG] Stored preds | strategy=fpt | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating bag...
[DEBUG] Stored preds | strategy=bag | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_1...
[DEBUG] Stored preds | strategy=ngram_1 | iteration=2 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
Evaluating ngram_2...
[DEBUG] Stored preds | strategy=ngram_2 | iteration=2 | preds_len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__', '__stop__', 'b']
Evaluating ngram_3...
[DEBUG] Stored preds | strategy=ngram_3 | iteration=2 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating ngram_4...
[DEBUG] Stored preds | strategy=ngram_4 | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_5...
[DEBUG] Stored preds | strategy=ngram_5 | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_6...
[DEBUG] Stored preds | strategy=ngram_6 | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_7...
[DEBUG] Stored preds | strategy=ngram_7 | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_8...
[DEBUG] Stored preds | strategy=ngram_8 | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_9...
[DEBUG] Stored preds | strategy=ngram_9 | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating fallback fpt->ngram...
[DEBUG] Stored preds | strategy=fallback fpt->ngram | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating hard voting...
[DEBUG] Stored preds | strategy=hard voting | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4) | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8) | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5) | iteration=2 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4)* | iteration=2 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8)* | iteration=2 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5)* | iteration=2 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating alergia...
[DEBUG] Stored preds | strategy=alergia | iteration=2 | preds_len=91 | sample=['b', '__stop__', 'b', '__stop__', 'b', 'b', '__stop__', 'b', '__stop__', 'b']
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 3.9013
Evaluating on validation set...
New best validation accuracy: 23.08%
Epoch 2/20, Average Loss: 3.8533
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 3/20, Average Loss: 3.7842
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 4/20, Average Loss: 3.6646
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 23.08%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 3.4550
Evaluating on validation set...
New best validation accuracy: 32.97%
Epoch 2/20, Average Loss: 2.1398
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 3/20, Average Loss: 1.5721
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 4/20, Average Loss: 1.3367
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 32.97%
[DEBUG] NN stored preds | model=LSTM | iter=2 | preds_len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__', '__stop__', 'b']
[DEBUG] NN stored preds | model=transformer | iter=2 | preds_len=91 | sample=['a', 'b', 'b', 'b', 'b', 'a', 'b', 'b', '__stop__', 'a']
[ITER DEBUG] After iteration 2 summary counts (per strategy): {'actual': 2, 'fpt': 2, 'bag': 2, 'ngram_1': 2, 'ngram_2': 2, 'ngram_3': 2, 'ngram_4': 2, 'ngram_5': 2, 'ngram_6': 2, 'ngram_7': 2, 'ngram_8': 2, 'ngram_9': 2, 'fallback fpt->ngram': 2, 'hard voting': 2, 'soft voting (2, 3, 4)': 2, 'soft voting (2, 3, 5, 8)': 2, 'soft voting (2, 3, 4, 5)': 2, 'soft voting (2, 3, 4)*': 2, 'soft voting (2, 3, 5, 8)*': 2, 'soft voting (2, 3, 4, 5)*': 2, 'alergia': 2, 'LSTM': 2, 'transformer': 2}
[ITER DEBUG] sample preds | strategy=fpt | len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=bag | len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=ngram_1 | len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_2 | len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_3 | len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__']
Starting iteration 3/5...
[DEBUG] Stored baseline actual vector | iteration=3 | len=91 | sample=['a', 'a', 'a', 'a', '__stop__', 'a', 'a', 'b', '__stop__', 'b']
Training time for Alergia: 0.0001 seconds
Total training time for process miners: 0.0057 seconds
Training time for Bayesian Classifiers: 0.0002 seconds
Evaluating fpt...
[DEBUG] Stored preds | strategy=fpt | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating bag...
[DEBUG] Stored preds | strategy=bag | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_1...
[DEBUG] Stored preds | strategy=ngram_1 | iteration=3 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
Evaluating ngram_2...
[DEBUG] Stored preds | strategy=ngram_2 | iteration=3 | preds_len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__', '__stop__', 'b']
Evaluating ngram_3...
[DEBUG] Stored preds | strategy=ngram_3 | iteration=3 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating ngram_4...
[DEBUG] Stored preds | strategy=ngram_4 | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_5...
[DEBUG] Stored preds | strategy=ngram_5 | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_6...
[DEBUG] Stored preds | strategy=ngram_6 | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_7...
[DEBUG] Stored preds | strategy=ngram_7 | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_8...
[DEBUG] Stored preds | strategy=ngram_8 | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_9...
[DEBUG] Stored preds | strategy=ngram_9 | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating fallback fpt->ngram...
[DEBUG] Stored preds | strategy=fallback fpt->ngram | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating hard voting...
[DEBUG] Stored preds | strategy=hard voting | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4) | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8) | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5) | iteration=3 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4)* | iteration=3 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8)* | iteration=3 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5)* | iteration=3 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating alergia...
[DEBUG] Stored preds | strategy=alergia | iteration=3 | preds_len=91 | sample=['b', '__stop__', 'b', '__stop__', 'b', 'b', '__stop__', 'b', '__stop__', 'b']
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 3.8957
Evaluating on validation set...
New best validation accuracy: 15.38%
Epoch 2/20, Average Loss: 3.8382
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 3/20, Average Loss: 3.7529
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 4/20, Average Loss: 3.6101
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 15.38%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 3.2794
Evaluating on validation set...
New best validation accuracy: 28.57%
Epoch 2/20, Average Loss: 1.7811
Evaluating on validation set...
New best validation accuracy: 29.67%
Epoch 3/20, Average Loss: 1.2829
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 4/20, Average Loss: 1.1563
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 5/20, Average Loss: 1.0047
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 29.67%
[DEBUG] NN stored preds | model=LSTM | iter=3 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[DEBUG] NN stored preds | model=transformer | iter=3 | preds_len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a', '__stop__', 'b']
[ITER DEBUG] After iteration 3 summary counts (per strategy): {'actual': 3, 'fpt': 3, 'bag': 3, 'ngram_1': 3, 'ngram_2': 3, 'ngram_3': 3, 'ngram_4': 3, 'ngram_5': 3, 'ngram_6': 3, 'ngram_7': 3, 'ngram_8': 3, 'ngram_9': 3, 'fallback fpt->ngram': 3, 'hard voting': 3, 'soft voting (2, 3, 4)': 3, 'soft voting (2, 3, 5, 8)': 3, 'soft voting (2, 3, 4, 5)': 3, 'soft voting (2, 3, 4)*': 3, 'soft voting (2, 3, 5, 8)*': 3, 'soft voting (2, 3, 4, 5)*': 3, 'alergia': 3, 'LSTM': 3, 'transformer': 3}
[ITER DEBUG] sample preds | strategy=fpt | len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=bag | len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=ngram_1 | len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_2 | len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_3 | len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__']
Starting iteration 4/5...
[DEBUG] Stored baseline actual vector | iteration=4 | len=91 | sample=['a', 'a', 'a', 'a', '__stop__', 'a', 'a', 'b', '__stop__', 'b']
Training time for Alergia: 0.0001 seconds
Total training time for process miners: 0.0061 seconds
Training time for Bayesian Classifiers: 0.0001 seconds
Evaluating fpt...
[DEBUG] Stored preds | strategy=fpt | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating bag...
[DEBUG] Stored preds | strategy=bag | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_1...
[DEBUG] Stored preds | strategy=ngram_1 | iteration=4 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
Evaluating ngram_2...
[DEBUG] Stored preds | strategy=ngram_2 | iteration=4 | preds_len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__', '__stop__', 'b']
Evaluating ngram_3...
[DEBUG] Stored preds | strategy=ngram_3 | iteration=4 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating ngram_4...
[DEBUG] Stored preds | strategy=ngram_4 | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_5...
[DEBUG] Stored preds | strategy=ngram_5 | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_6...
[DEBUG] Stored preds | strategy=ngram_6 | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_7...
[DEBUG] Stored preds | strategy=ngram_7 | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_8...
[DEBUG] Stored preds | strategy=ngram_8 | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_9...
[DEBUG] Stored preds | strategy=ngram_9 | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating fallback fpt->ngram...
[DEBUG] Stored preds | strategy=fallback fpt->ngram | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating hard voting...
[DEBUG] Stored preds | strategy=hard voting | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4) | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8) | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5) | iteration=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4)* | iteration=4 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8)* | iteration=4 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5)* | iteration=4 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating alergia...
[DEBUG] Stored preds | strategy=alergia | iteration=4 | preds_len=91 | sample=['b', '__stop__', 'b', '__stop__', 'b', 'b', '__stop__', 'b', '__stop__', 'b']
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 3.8929
Evaluating on validation set...
New best validation accuracy: 23.08%
Epoch 2/20, Average Loss: 3.8353
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 3/20, Average Loss: 3.7497
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 4/20, Average Loss: 3.5988
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 23.08%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 3.6498
Evaluating on validation set...
New best validation accuracy: 26.37%
Epoch 2/20, Average Loss: 2.1029
Evaluating on validation set...
New best validation accuracy: 28.57%
Epoch 3/20, Average Loss: 1.5017
Evaluating on validation set...
New best validation accuracy: 29.67%
Epoch 4/20, Average Loss: 1.2173
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 5/20, Average Loss: 1.0832
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 6/20, Average Loss: 0.9792
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 29.67%
[DEBUG] NN stored preds | model=LSTM | iter=4 | preds_len=91 | sample=['a', '__stop__', '__stop__', '__stop__', '__stop__', 'a', '__stop__', '__stop__', '__stop__', 'a']
[DEBUG] NN stored preds | model=transformer | iter=4 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
[ITER DEBUG] After iteration 4 summary counts (per strategy): {'actual': 4, 'fpt': 4, 'bag': 4, 'ngram_1': 4, 'ngram_2': 4, 'ngram_3': 4, 'ngram_4': 4, 'ngram_5': 4, 'ngram_6': 4, 'ngram_7': 4, 'ngram_8': 4, 'ngram_9': 4, 'fallback fpt->ngram': 4, 'hard voting': 4, 'soft voting (2, 3, 4)': 4, 'soft voting (2, 3, 5, 8)': 4, 'soft voting (2, 3, 4, 5)': 4, 'soft voting (2, 3, 4)*': 4, 'soft voting (2, 3, 5, 8)*': 4, 'soft voting (2, 3, 4, 5)*': 4, 'alergia': 4, 'LSTM': 4, 'transformer': 4}
[ITER DEBUG] sample preds | strategy=fpt | len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=bag | len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=ngram_1 | len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_2 | len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_3 | len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__']
Starting iteration 5/5...
[DEBUG] Stored baseline actual vector | iteration=5 | len=91 | sample=['a', 'a', 'a', 'a', '__stop__', 'a', 'a', 'b', '__stop__', 'b']
Training time for Alergia: 0.0001 seconds
Total training time for process miners: 0.0057 seconds
Training time for Bayesian Classifiers: 0.0001 seconds
Evaluating fpt...
[DEBUG] Stored preds | strategy=fpt | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating bag...
[DEBUG] Stored preds | strategy=bag | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_1...
[DEBUG] Stored preds | strategy=ngram_1 | iteration=5 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
Evaluating ngram_2...
[DEBUG] Stored preds | strategy=ngram_2 | iteration=5 | preds_len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__', '__stop__', 'b']
Evaluating ngram_3...
[DEBUG] Stored preds | strategy=ngram_3 | iteration=5 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating ngram_4...
[DEBUG] Stored preds | strategy=ngram_4 | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_5...
[DEBUG] Stored preds | strategy=ngram_5 | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_6...
[DEBUG] Stored preds | strategy=ngram_6 | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_7...
[DEBUG] Stored preds | strategy=ngram_7 | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_8...
[DEBUG] Stored preds | strategy=ngram_8 | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating ngram_9...
[DEBUG] Stored preds | strategy=ngram_9 | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating fallback fpt->ngram...
[DEBUG] Stored preds | strategy=fallback fpt->ngram | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating hard voting...
[DEBUG] Stored preds | strategy=hard voting | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4) | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8) | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5) | iteration=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
Evaluating soft voting (2, 3, 4)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4)* | iteration=5 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 5, 8)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 5, 8)* | iteration=5 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating soft voting (2, 3, 4, 5)*...
[DEBUG] Stored preds | strategy=soft voting (2, 3, 4, 5)* | iteration=5 | preds_len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__', '__stop__', 'b']
Evaluating alergia...
[DEBUG] Stored preds | strategy=alergia | iteration=5 | preds_len=91 | sample=['b', '__stop__', 'b', '__stop__', 'b', 'b', '__stop__', 'b', '__stop__', 'b']
Training and evaluating LSTM model...
Epoch 1/20, Average Loss: 3.8968
Evaluating on validation set...
New best validation accuracy: 15.38%
Epoch 2/20, Average Loss: 3.8440
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 3/20, Average Loss: 3.7672
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 4/20, Average Loss: 3.6308
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 15.38%
Training and evaluating transformer model...
Epoch 1/20, Average Loss: 3.5270
Evaluating on validation set...
New best validation accuracy: 23.08%
Epoch 2/20, Average Loss: 1.9842
Evaluating on validation set...
New best validation accuracy: 29.67%
Epoch 3/20, Average Loss: 1.4094
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 1/3
Epoch 4/20, Average Loss: 1.1855
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 2/3
Epoch 5/20, Average Loss: 1.0863
Evaluating on validation set...
Validation accuracy did not improve. Patience counter: 3/3
Early stopping triggered. Restoring best model weights.
Best validation accuracy: 29.67%
[DEBUG] NN stored preds | model=LSTM | iter=5 | preds_len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[DEBUG] NN stored preds | model=transformer | iter=5 | preds_len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a', '__stop__', 'b']
[ITER DEBUG] After iteration 5 summary counts (per strategy): {'actual': 5, 'fpt': 5, 'bag': 5, 'ngram_1': 5, 'ngram_2': 5, 'ngram_3': 5, 'ngram_4': 5, 'ngram_5': 5, 'ngram_6': 5, 'ngram_7': 5, 'ngram_8': 5, 'ngram_9': 5, 'fallback fpt->ngram': 5, 'hard voting': 5, 'soft voting (2, 3, 4)': 5, 'soft voting (2, 3, 5, 8)': 5, 'soft voting (2, 3, 4, 5)': 5, 'soft voting (2, 3, 4)*': 5, 'soft voting (2, 3, 5, 8)*': 5, 'soft voting (2, 3, 4, 5)*': 5, 'alergia': 5, 'LSTM': 5, 'transformer': 5}
[ITER DEBUG] sample preds | strategy=fpt | len=91 | sample=['b', 'a', 'a', '__stop__', '__stop__', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=bag | len=91 | sample=['b', 'a', 'a', 'a', 'a', 'b', 'a', 'a']
[ITER DEBUG] sample preds | strategy=ngram_1 | len=91 | sample=['__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_2 | len=91 | sample=['b', '__stop__', '__stop__', '__stop__', '__stop__', 'b', '__stop__', '__stop__']
[ITER DEBUG] sample preds | strategy=ngram_3 | len=91 | sample=['b', 'a', '__stop__', '__stop__', '__stop__', 'b', 'a', '__stop__']

                        Model  Mean Accuracy (%)   Std  Top-2 (%)  Top-3 (%)  PP Arithm  PP Harmo  PP Median  PP Q1  PP Q3  States  Pred Time  Train Time
0                         fpt              13.33  0.00      22.22      28.15        inf      6.63        inf   2.34    inf    11.0       6.98        2.62
1                         bag              13.74  0.00      22.90      32.06        inf      7.31        inf   2.88    inf     4.0       7.46        2.24
2                     ngram_1               9.09  0.00      36.36      61.82        inf      4.25       3.06   3.00    inf     1.0      10.92        2.89
3                     ngram_2              22.11  0.00      51.58      87.37        inf      5.02       5.13   3.49    inf     3.0      11.84        2.08
4                     ngram_3              26.32  0.00      42.11      56.84        inf      7.14        inf   2.64    inf     7.0      10.02        1.94
5                     ngram_4              26.32  0.00      44.21      65.26        inf      6.77        inf   2.34    inf    10.0       9.49        2.02
6                     ngram_5              26.32  0.00      44.21      65.26        inf      6.63        inf   2.34    inf    11.0       9.10       10.68
7                     ngram_6              26.32  0.00      44.21      65.26        inf      6.63        inf   2.34    inf    11.0       9.25        1.79
8                     ngram_7              26.32  0.00      44.21      65.26        inf      6.63        inf   2.34    inf    11.0      11.68        1.79
9                     ngram_8              26.32  0.00      44.21      65.26        inf      6.63        inf   2.34    inf    11.0       8.98        1.71
10                    ngram_9              26.32  0.00      44.21      65.26        inf      6.63        inf   2.34    inf    11.0       8.96        1.77
11        fallback fpt->ngram              19.09  0.00      33.64      47.27        inf      6.63        inf   2.34    inf     NaN      15.58        6.03
12                hard voting              19.09  0.00      19.09      19.09       0.00      0.00       0.00   0.00   0.00     NaN      42.53        9.53
13      soft voting (2, 3, 4)              19.09  0.00      33.64      50.91        inf      6.10        inf   2.56    inf     NaN      33.57        9.40
14   soft voting (2, 3, 5, 8)              19.09  0.00      33.64      50.91        inf      6.06        inf   2.51    inf     NaN      39.37       11.05
15   soft voting (2, 3, 4, 5)              19.09  0.00      33.64      50.91        inf      6.06        inf   2.51    inf     NaN      38.31       18.28
16     soft voting (2, 3, 4)*              17.27  0.00      30.91      46.36        inf      7.08        inf   2.87    inf     NaN      25.69        9.42
17  soft voting (2, 3, 5, 8)*              17.27  0.00      30.91      46.36        inf      7.08        inf   2.86    inf     NaN      30.79       11.05
18  soft voting (2, 3, 4, 5)*              17.27  0.00      30.91      46.36        inf      7.08        inf   2.86    inf     NaN      28.22       10.76
19                    alergia              24.18  0.00      63.74      95.60        inf       inf        inf    inf    inf     3.0       4.87      130.22
20                       LSTM              20.88  4.76      55.82      85.71      47.13     47.13      47.07  46.94  47.39     0.0      52.18      399.90
21                transformer              30.77  1.39      52.97      78.24       8.93      7.19       7.89   5.47  11.65     0.0      45.82      443.65
22             bayesian train                NaN   NaN        NaN        NaN        NaN       NaN        NaN    NaN    NaN     NaN        NaN         NaN
23              bayesian test                NaN   NaN        NaN        NaN        NaN       NaN        NaN    NaN    NaN     NaN        NaN         NaN
24               bayesian t+t                NaN   NaN        NaN        NaN        NaN       NaN        NaN    NaN    NaN     NaN        NaN         NaN
25    bayesian test nonsingle                NaN   NaN        NaN        NaN        NaN       NaN        NaN    NaN    NaN     NaN        NaN         NaN
26     bayesian t+t nonsingle                NaN   NaN        NaN        NaN        NaN       NaN        NaN    NaN    NaN     NaN        NaN         NaN
[FINAL DEBUG] Completed all iterations. Prediction vectors stored per strategy:
[FINAL DEBUG] strategy=actual | iterations_stored=5 | total_predictions=455 | comparision_ratio=1.0
[FINAL DEBUG] strategy=fpt | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.64
[FINAL DEBUG] strategy=bag | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.6
[FINAL DEBUG] strategy=ngram_1 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.4
[FINAL DEBUG] strategy=ngram_2 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.84
[FINAL DEBUG] strategy=ngram_3 | iterations_stored=5 | total_predictions=455 | comparision_ratio=1.0
[FINAL DEBUG] strategy=ngram_4 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.92
[FINAL DEBUG] strategy=ngram_5 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.92
[FINAL DEBUG] strategy=ngram_6 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.92
[FINAL DEBUG] strategy=ngram_7 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.92
[FINAL DEBUG] strategy=ngram_8 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.92
[FINAL DEBUG] strategy=ngram_9 | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.92
[FINAL DEBUG] strategy=fallback fpt->ngram | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=hard voting | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=soft voting (2, 3, 4) | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=soft voting (2, 3, 5, 8) | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=soft voting (2, 3, 4, 5) | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=soft voting (2, 3, 4)* | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=soft voting (2, 3, 5, 8)* | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=soft voting (2, 3, 4, 5)* | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
[FINAL DEBUG] strategy=alergia | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.6
[FINAL DEBUG] strategy=LSTM | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.704
[FINAL DEBUG] strategy=transformer | iterations_stored=5 | total_predictions=455 | comparision_ratio=0.76
